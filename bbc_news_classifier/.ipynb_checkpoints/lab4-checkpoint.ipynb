{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c70361c7",
   "metadata": {},
   "source": [
    "### CIS 9: Lab 4\n",
    "Natural Language Processing: Multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1fef7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Name: Nitya Kashyap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e95b350",
   "metadata": {},
   "source": [
    "In this lab you will train an ML model to categorize news articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "984e42a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196de76b",
   "metadata": {},
   "source": [
    "The [BBC News](https://www.bbc.com/news) is a British news organization that reports on current events around the world. In this exercise you will train an NLP model to categorize the topics of news articles. The model will determine whether a news articles is on sports, politics, etc.\n",
    "\n",
    "The training data are from BBC News and have been preprocessed for ML. The training input file is `news.csv` ([source](https://www.kaggle.com/datasets/dheemanthbhat/bbc-full-text-preprocessed?select=docs_stage_3_preprocessed.csv))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63724b6",
   "metadata": {},
   "source": [
    "1. __Read data from _news.csv_ into a DataFrame__.<br>\n",
    "Then __print the number of rows and columns of the DataFrame__<br>\n",
    "and __print the first 5 rows__ to see what the data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63381186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows, columns: (2205, 24)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DocId</th>\n",
       "      <th>DocTextlen</th>\n",
       "      <th>DocText</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADP</th>\n",
       "      <th>ADV</th>\n",
       "      <th>AUX</th>\n",
       "      <th>CCONJ</th>\n",
       "      <th>DET</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>...</th>\n",
       "      <th>PUNCT</th>\n",
       "      <th>SCONJ</th>\n",
       "      <th>SYM</th>\n",
       "      <th>VERB</th>\n",
       "      <th>X</th>\n",
       "      <th>INTJ</th>\n",
       "      <th>DocType</th>\n",
       "      <th>FileSize</th>\n",
       "      <th>FilePath</th>\n",
       "      <th>DocCat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B_001</td>\n",
       "      <td>2553</td>\n",
       "      <td>ad sale boost time_warner profit quarterly pro...</td>\n",
       "      <td>31</td>\n",
       "      <td>61</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>28</td>\n",
       "      <td>114</td>\n",
       "      <td>...</td>\n",
       "      <td>55</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Business</td>\n",
       "      <td>2560</td>\n",
       "      <td>../input/bbc-full-text-document-classification...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B_002</td>\n",
       "      <td>2248</td>\n",
       "      <td>dollar gain greenspan speech dollar hit high l...</td>\n",
       "      <td>33</td>\n",
       "      <td>54</td>\n",
       "      <td>15.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>44</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>43</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Business</td>\n",
       "      <td>2252</td>\n",
       "      <td>../input/bbc-full-text-document-classification...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B_003</td>\n",
       "      <td>1547</td>\n",
       "      <td>yukos unit buyer face loan claim owner embattl...</td>\n",
       "      <td>11</td>\n",
       "      <td>32</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>25</td>\n",
       "      <td>71</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Business</td>\n",
       "      <td>1552</td>\n",
       "      <td>../input/bbc-full-text-document-classification...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B_004</td>\n",
       "      <td>2395</td>\n",
       "      <td>high fuel price hit ba profit british_airways ...</td>\n",
       "      <td>36</td>\n",
       "      <td>53</td>\n",
       "      <td>16.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>26</td>\n",
       "      <td>114</td>\n",
       "      <td>...</td>\n",
       "      <td>62</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Business</td>\n",
       "      <td>2412</td>\n",
       "      <td>../input/bbc-full-text-document-classification...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B_005</td>\n",
       "      <td>1565</td>\n",
       "      <td>pernod takeover talk lift domecq share uk drin...</td>\n",
       "      <td>15</td>\n",
       "      <td>32</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14</td>\n",
       "      <td>68</td>\n",
       "      <td>...</td>\n",
       "      <td>35</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Business</td>\n",
       "      <td>1570</td>\n",
       "      <td>../input/bbc-full-text-document-classification...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   DocId  DocTextlen                                            DocText  ADJ  \\\n",
       "0  B_001        2553  ad sale boost time_warner profit quarterly pro...   31   \n",
       "1  B_002        2248  dollar gain greenspan speech dollar hit high l...   33   \n",
       "2  B_003        1547  yukos unit buyer face loan claim owner embattl...   11   \n",
       "3  B_004        2395  high fuel price hit ba profit british_airways ...   36   \n",
       "4  B_005        1565  pernod takeover talk lift domecq share uk drin...   15   \n",
       "\n",
       "   ADP   ADV   AUX  CCONJ  DET  NOUN  ...  PUNCT  SCONJ   SYM  VERB    X  \\\n",
       "0   61  15.0  15.0   13.0   28   114  ...     55    3.0   9.0    53  0.0   \n",
       "1   54  15.0  21.0    9.0   44    99  ...     43    5.0   2.0    43  0.0   \n",
       "2   32   3.0  15.0    4.0   25    71  ...     26    3.0   4.0    42  0.0   \n",
       "3   53  16.0  17.0    8.0   26   114  ...     62    8.0  10.0    45  0.0   \n",
       "4   32   5.0  13.0    8.0   14    68  ...     35    5.0   3.0    26  0.0   \n",
       "\n",
       "   INTJ   DocType  FileSize  \\\n",
       "0   0.0  Business      2560   \n",
       "1   0.0  Business      2252   \n",
       "2   0.0  Business      1552   \n",
       "3   0.0  Business      2412   \n",
       "4   0.0  Business      1570   \n",
       "\n",
       "                                            FilePath  DocCat  \n",
       "0  ../input/bbc-full-text-document-classification...       0  \n",
       "1  ../input/bbc-full-text-document-classification...       0  \n",
       "2  ../input/bbc-full-text-document-classification...       0  \n",
       "3  ../input/bbc-full-text-document-classification...       0  \n",
       "4  ../input/bbc-full-text-document-classification...       0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"news.csv\")\n",
    "print(\"rows, columns:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc866d13",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b64c9fd",
   "metadata": {},
   "source": [
    "2. Data cleaning\n",
    "\n",
    "2a. __Print all the column labels__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d70f41c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column labels: Index(['DocId', 'DocTextlen', 'DocText', 'ADJ', 'ADP', 'ADV', 'AUX', 'CCONJ',\n",
      "       'DET', 'NOUN', 'NUM', 'PART', 'PRON', 'PROPN', 'PUNCT', 'SCONJ', 'SYM',\n",
      "       'VERB', 'X', 'INTJ', 'DocType', 'FileSize', 'FilePath', 'DocCat'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"column labels:\", df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d3e0a6",
   "metadata": {},
   "source": [
    "2b. Since the data have been preprocessed, each row or news article has multiple features, some of which we don't need for our ML training purpose.\n",
    "\n",
    "The column labels that are all uppercase such as ADJ, ADV, NOUN... denote the count of adjectives, adverbs, nouns... that are in the article. We can remove these columns because Parts of Speech are not used by the MultinomialMB model.\n",
    "\n",
    "The columns we want to keep are:\n",
    "- DocText: contains the news articles\n",
    "- DocType: categories of the news articles, as strings\n",
    "- DocCat: categories of the news articles, as numbers\n",
    "\n",
    "Given that the columns containing Parts of Speech can be removed due to the reason above, create a Raw NBConvert cell to __explain why the other columns can also be removed__, so that we only keep the 3 columns DocText, DocType, and DocCat."
   ]
  },
  {
   "cell_type": "raw",
   "id": "90f676bf",
   "metadata": {},
   "source": [
    "DocId and FilePath should be removed because they identify unique entries, which does not help the ML model see any patterns. FileSize and DocTextlen can be removed because these two features do not provide any insight into the to the topic/subject category of the article, and therefore will not help the ML model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436ca1f0",
   "metadata": {},
   "source": [
    "2c. __Create a DataFrame with the 3 columns__ that you want to keep.<br>\n",
    "Then __print the first 5 rows__ of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cca8808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DocText</th>\n",
       "      <th>DocType</th>\n",
       "      <th>DocCat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ad sale boost time_warner profit quarterly pro...</td>\n",
       "      <td>Business</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dollar gain greenspan speech dollar hit high l...</td>\n",
       "      <td>Business</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yukos unit buyer face loan claim owner embattl...</td>\n",
       "      <td>Business</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>high fuel price hit ba profit british_airways ...</td>\n",
       "      <td>Business</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pernod takeover talk lift domecq share uk drin...</td>\n",
       "      <td>Business</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             DocText   DocType  DocCat\n",
       "0  ad sale boost time_warner profit quarterly pro...  Business       0\n",
       "1  dollar gain greenspan speech dollar hit high l...  Business       0\n",
       "2  yukos unit buyer face loan claim owner embattl...  Business       0\n",
       "3  high fuel price hit ba profit british_airways ...  Business       0\n",
       "4  pernod takeover talk lift domecq share uk drin...  Business       0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=[\"DocId\", \"DocTextlen\", \"ADJ\", \"ADP\", \"ADV\", \"AUX\", \"CCONJ\",\n",
    "       \"DET\", \"NOUN\", \"NUM\", \"PART\", \"PRON\", \"PROPN\", \"PUNCT\", \"SCONJ\", \"SYM\",\n",
    "       \"VERB\", \"X\", \"INTJ\", \"FileSize\", \"FilePath\"], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2f5c58",
   "metadata": {},
   "source": [
    "2d. __Shorten the column labels__ by removing the 'Doc' from each label and lowercase all letters.<br>\n",
    "Then __print the first 5 rows__ of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43c42752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ad sale boost time_warner profit quarterly pro...</td>\n",
       "      <td>Business</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dollar gain greenspan speech dollar hit high l...</td>\n",
       "      <td>Business</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yukos unit buyer face loan claim owner embattl...</td>\n",
       "      <td>Business</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>high fuel price hit ba profit british_airways ...</td>\n",
       "      <td>Business</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pernod takeover talk lift domecq share uk drin...</td>\n",
       "      <td>Business</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text      type  cat\n",
       "0  ad sale boost time_warner profit quarterly pro...  Business    0\n",
       "1  dollar gain greenspan speech dollar hit high l...  Business    0\n",
       "2  yukos unit buyer face loan claim owner embattl...  Business    0\n",
       "3  high fuel price hit ba profit british_airways ...  Business    0\n",
       "4  pernod takeover talk lift domecq share uk drin...  Business    0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = df.columns.str.replace(\"Doc\", \"\").str.lower()\n",
    "# df.columns = df.columns.str.lower()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478c5ce6",
   "metadata": {},
   "source": [
    "2e. __Check and remove any NaN__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b61ba24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check for NaN:\n",
      "text    0\n",
      "type    0\n",
      "cat     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"check for NaN:\")\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0455b652",
   "metadata": {},
   "source": [
    "there are no NaNs present in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea79dfd",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6a79cd",
   "metadata": {},
   "source": [
    "3. Analyze data\n",
    "\n",
    "3b. __Show the count of each DocType categories__<br>\n",
    "and then __show the count of each DocCat categories__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f744e8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DocType categories:\n",
      "type\n",
      "Business         510\n",
      "Entertainment    381\n",
      "Politics         413\n",
      "Sport            506\n",
      "Tech             395\n",
      "Name: type, dtype: int64\n",
      "\n",
      "DocCat categories:\n",
      "cat\n",
      "0    510\n",
      "1    381\n",
      "2    413\n",
      "3    506\n",
      "4    395\n",
      "Name: cat, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"DocType categories:\")\n",
    "print(df.groupby(\"type\").type.count())\n",
    "\n",
    "print(\"\\nDocCat categories:\")\n",
    "print(df.groupby(\"cat\").cat.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8575542a",
   "metadata": {},
   "source": [
    "3b. The output seems to show that the there is a one-to-one correspondence between the strings in DocType and numbers in DocCat.\n",
    "\n",
    "Write code to __print the proof that they correspond with each other__. This means to show that all \"Business\" DoctType are 0 in DocCat, all \"Sport\" DocType are 3 in DocCat, etc.\n",
    "\n",
    "_Challenge: write a loop to check and print the 5 results, instead of copy-paste code 5 times_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a938117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookup table: {0: 'Business', 1: 'Entertainment', 2: 'Politics', 3: 'Sport', 4: 'Tech'}\n",
      "\n",
      "category 0 matches type Business in 510 rows\n",
      "or equivalently: there are  0 rows in which category 0 and type Business do not match\n",
      "\n",
      "category 1 matches type Entertainment in 381 rows\n",
      "or equivalently: there are  0 rows in which category 1 and type Entertainment do not match\n",
      "\n",
      "category 2 matches type Politics in 413 rows\n",
      "or equivalently: there are  0 rows in which category 2 and type Politics do not match\n",
      "\n",
      "category 3 matches type Sport in 506 rows\n",
      "or equivalently: there are  0 rows in which category 3 and type Sport do not match\n",
      "\n",
      "category 4 matches type Tech in 395 rows\n",
      "or equivalently: there are  0 rows in which category 4 and type Tech do not match\n"
     ]
    }
   ],
   "source": [
    "# in all rows, the strings in type corresponds with the numbers in cat\n",
    "lookup = dict(zip(df.cat.unique(), df.type.unique()))\n",
    "print(\"lookup table:\", lookup)\n",
    "for k,v in lookup.items():\n",
    "#     print(k,v)\n",
    "    print(\"\\ncategory\", k, \"matches type\", v, \"in\", df[(df.cat == k) & (df.type == v)].shape[0], \"rows\")\n",
    "    print(\"or equivalently: there are \", df[(df.cat == k) & (df.type != v)].shape[0], \"rows in which category\", k, \"and type\", v, \"do not match\") # should be zero"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7f90bfff",
   "metadata": {},
   "source": [
    "This matches the exact counts of the categories seen previously. Each of the 510 business rows also is in Cat 0. Similarly, the rest of the types also match up with the expected categories. Or equivalently, there are no rows in which each of the categories does not match up with its expected type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8647499",
   "metadata": {},
   "source": [
    "3c. __Create a lookup table__ which is a dictionary where each unique DocCat value is the key, and the corresponding DocType string is the value.<br>\n",
    "Then __print the lookup table__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "576e94b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Business', 1: 'Entertainment', 2: 'Politics', 3: 'Sport', 4: 'Tech'}\n"
     ]
    }
   ],
   "source": [
    "# already set up\n",
    "print(lookup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408e118f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcbab3f",
   "metadata": {},
   "source": [
    "4. Preparing data for ML\n",
    "\n",
    "4a. Now that you've proven that DocType and DocCat have the same data, choose the column that makes it less work for you to use the ML model, then __remove one of the columns__. <br>\n",
    "Then __show the first 5 rows__ of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e76a884d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ad sale boost time_warner profit quarterly pro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dollar gain greenspan speech dollar hit high l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yukos unit buyer face loan claim owner embattl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>high fuel price hit ba profit british_airways ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pernod takeover talk lift domecq share uk drin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  cat\n",
       "0  ad sale boost time_warner profit quarterly pro...    0\n",
       "1  dollar gain greenspan speech dollar hit high l...    0\n",
       "2  yukos unit buyer face loan claim owner embattl...    0\n",
       "3  high fuel price hit ba profit british_airways ...    0\n",
       "4  pernod takeover talk lift domecq share uk drin...    0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=[\"type\"], inplace =True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d628d12",
   "metadata": {},
   "source": [
    "4b. __Create the X and y datasets__ and __print the shape__ of each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5649e0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X: (2205,) shape of y: (2205,)\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "X = df.text\n",
    "y = df.cat\n",
    "print(\"shape of X:\", X.shape, \"shape of y:\", y.shape)\n",
    "# print(type(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c84907",
   "metadata": {},
   "source": [
    "4c. Since the training data are already preprocessed. We want to take a look at one sample news article to see if there needs to be further preprocessing.\n",
    "\n",
    "__Print the news article at row 0__ to inspect it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33e53a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ad sale boost time_warner profit quarterly profit media giant timewarner jump 76 $ 1.13bn £ 600 m month december $ 639 m year early firm big investor google benefit sale high speed internet connection high advert sale timewarner say fourth quarter sale rise 2 $ 11.1bn $ 10.9bn profit buoy gain offset profit dip warner_bros user aol time_warner say friday own 8 search engine google internet business aol mixed fortune lose 464,000 subscriber fourth quarter profit low precede quarter company say aol underlie profit exceptional item rise 8 strong internet advertising revenue hope increase subscriber offer online service free timewarner internet customer try sign aol exist customer high speed broadband timewarner restate 2000 2003 result follow probe the_us_securities_exchange_commission sec close conclude time_warner's fourth quarter profit slightly well analyst expectation film division see profit slump 27 $ 284 m help box office flop alexander catwoman sharp contrast year early final film lord rings trilogy boost result year timewarner post profit $ 3.36bn 27 2003 performance revenue grow 6.4 $ 42.09bn financial performance strong meet exceed year objective greatly enhance flexibility chairman chief executive richard_parsons say 2005 timewarner project operate earning growth 5 expect high revenue wide profit margin timewarner restate account effort resolve inquiry aol market regulator offer pay $ 300 m settle charge deal review sec company say unable estimate need set aside legal reserve previously set $ 500 m. intend adjust way account deal german music publisher bertelsmann purchase stake aol_europe report advertising revenue book sale stake aol_europe loss value stake\n"
     ]
    }
   ],
   "source": [
    "print(df.text[0])\n",
    "# or df.at[0, 'text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bec2a92",
   "metadata": {},
   "source": [
    "4d. The preprocessing that we've discussed in class are related to stop words and stemming.<br>\n",
    "\n",
    "__Create a Raw NBConvert cell to explain__:\n",
    "- Does it look like stop words have been removed? Give examples from the text.\n",
    "- Does it look like stemming was applied? Give examples from the text."
   ]
  },
  {
   "cell_type": "raw",
   "id": "b4b5ebf8",
   "metadata": {},
   "source": [
    "It looks like the stop words have been removed. There are no articles such as \"a\", \"the\", etc., which a normal news article would have much of. It looks like stemming was applied too. For example, there seem to be no verbs in past tense. Verbs like \"jump\", \"settle\", and \"purchase\" are all stemmed verbs.\n",
    "\n",
    "NOOOO CLARE SAYS STEMMING WAS NOT APPLIED! (WORDS LIKE FLEXIBILITY AND ADVERTISING WERE NOT STEMMED) \n",
    "-_-\n",
    "clare says that there was no need to stem it here because the data seemed mostly already preprocessed and the accuracy of the model was pretty high without the stemming. if it wasn't she said she'd try to stem it to see if that improved accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2402320d",
   "metadata": {},
   "source": [
    "4e. __Convert the preprocessed data to numbers__ so it's ready for the ML model.<br>\n",
    "Then __print the shape of the X dataset__ that will be used with the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed8169ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2205, 28975)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer()\n",
    "vect.fit(X)\n",
    "X_vectors = vect.transform(X)\n",
    "# print(X_vectors)\n",
    "X_vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b38ca54",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd75688",
   "metadata": {},
   "source": [
    "5. Train and test the model\n",
    "\n",
    "5a. __Create X and y training and testing datasets__.<br>\n",
    "Then __print the shape of each dataset__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f573d2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X training dataset size: (1764, 28975) X testing dataset size: (441, 28975) y training dataset size: (1764,) y testing dataset size: (441,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_vectors, y, test_size = 0.2)\n",
    "print(\"X training dataset size:\", X_train.shape, \"X testing dataset size:\", X_test.shape, \"y training dataset size:\", y_train.shape, \"y testing dataset size:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4815c02",
   "metadata": {},
   "source": [
    "5b. __Train and test the ML model__<br>\n",
    "and then __print the accuracy measurements__.\n",
    "\n",
    "_There are more than one accuracy measurement._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "560c2358",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.981859410430839\n",
      "confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[107,   0,   2,   0,   1],\n",
       "       [  0,  61,   1,   0,   2],\n",
       "       [  1,   0,  89,   0,   0],\n",
       "       [  0,   0,   0, 102,   0],\n",
       "       [  0,   0,   1,   0,  74]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_predict = classifier.predict(X_test)\n",
    "\n",
    "# measure accuracy\n",
    "print(\"accuracy score:\", metrics.accuracy_score(y_test, y_predict))\n",
    "print(\"confusion matrix:\")\n",
    "metrics.confusion_matrix(y_test, y_predict, labels=list(lookup.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2307f708",
   "metadata": {},
   "source": [
    "5c. Create a Raw NBConvert cell to __discuss whether the accuracy measurements agree with each other__."
   ]
  },
  {
   "cell_type": "raw",
   "id": "e74bbfa2",
   "metadata": {},
   "source": [
    "The high accuracy score indicates the model is pretty accurate. This seems to agree with the confusion matrix, which shows that very few articles were categorized wrongly, and most were correctly categorized (the counts along the diagonal of the matrix are much greater than the rest)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df02be2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f28d74",
   "metadata": {},
   "source": [
    "6. Real life testing of the model you've trained.\n",
    "\n",
    "6a. __Print the lookup table__ you created in step 3c, which shows the corresponding values of the DocType and DocCat columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "82554d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Business', 1: 'Entertainment', 2: 'Politics', 3: 'Sport', 4: 'Tech'}\n"
     ]
    }
   ],
   "source": [
    "print(lookup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebfb3ae",
   "metadata": {},
   "source": [
    "6b. One advantage of working in NLP is that it's easier to come up with testing data. \n",
    "\n",
    "1. Go to the [BBC News](https://www.bbc.com/news) website to find the different types of news categories.<br>\n",
    "2. __Choose 3 of the news categories__ in the BBC web page header that match the categories that the ML model has learned.<br>\n",
    "3. For each category, click on the category link to __find today's news articles in that category__.<br>\n",
    "> - Then click to open an article and __copy the first 4-5 paragraphs of the article__.<br>\n",
    "> - Create a Code cell and paste the paragraphs into a Python string.\n",
    "\n",
    "_You should end up with 3 Code cells, each has a Python string which is the 4-5 paragraphs of a news article._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2d4553ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "entertainment_article = '''In the darkest corner of a grand museum that looks like a neo-classical palace lies a not-so-secret room.\n",
    "It is filled with statues of Congolese people, which have been regarded as racist, that were once part of the permanent exhibition.\n",
    "Schoolchildren on educational tours file past the Leopard Man, men with spears and women almost naked.\n",
    "This is the Africa Museum in Tervuren, just outside Brussels, and until recently those sculptures were part of the permanent exhibition.\n",
    "After facing years of heavy criticism nationally and internationally, the museum worked with a group of experts from the African diaspora in Belgium to rethink the controversial statues on display.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "61efbb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_article = '''Thousands of Reddit communities will be inaccessible on Monday in protest at how the site is being run.\n",
    "Reddit is introducing controversial charges to developers of third-party apps, which are used to browse the social media platform.\n",
    "But this has resulted in a backlash, with moderators of some of the biggest subreddits making their communities private for 48 hours in protest.\n",
    "Almost 3,500 subreddits will be inaccessible as a result.\n",
    "A subreddit is the name given to a forum within the Reddit platform - effectively a community of people who gather to discuss a particular interest.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "be7a4502",
   "metadata": {},
   "outputs": [],
   "source": [
    "sport_article = '''Novak Djokovic says it is not down to him to decide if he is the greatest player of all time after he won a men's record 23rd Grand Slam title.\n",
    "Serbia's Djokovic won the French Open on Sunday, moving him one clear of Rafael Nadal in terms of men's majors.\n",
    "He is level with Serena Williams on 23 and could equal Margaret Court's all-time record of 24 at Wimbledon in July.\n",
    "\"I don't want to enter in these discussions. I'm writing my own history,\" Djokovic, 36, said.\n",
    "\"I don't want to say I am the greatest. I leave those discussions to someone else.\"'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332a0367",
   "metadata": {},
   "source": [
    "6c. __Create a DataFrame from the 3 Python strings__.<br>\n",
    "Then __print the DataFrame__.\n",
    "\n",
    "_An example DataFrame is shown below, from news articles on 6/3. Your text will be different._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "dcdd8072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In the darkest corner of a grand museum that l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thousands of Reddit communities will be inacce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Novak Djokovic says it is not down to him to d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  In the darkest corner of a grand museum that l...\n",
       "1  Thousands of Reddit communities will be inacce...\n",
       "2  Novak Djokovic says it is not down to him to d..."
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.DataFrame(columns=[\"text\"], data=[[entertainment_article], [tech_article], [sport_article]])\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17156442",
   "metadata": {},
   "source": [
    "6d. __Test the ML model__ that you've trained with your new data in the DataFrame.\n",
    "\n",
    "This means:\n",
    "- preprocess the new data (your answer in step 4d will determine how you preprocess the new data).\n",
    "- convert the new data to numbers\n",
    "- test the model with the data\n",
    "- print the categories of news  that the model predicted. Use the lookup table to convert the numeric result from the model into the category string.\n",
    "Example:<br>`\n",
    "Article 1 : Sport\n",
    "Article 2 : Business\n",
    "Article 3 : Tech\n",
    "`\n",
    "\n",
    "_You'll need 4 Code cells, one for each step above_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ecf61e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>darkest corner grand museum look like neo clas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thousand reddit commun inaccess monday protest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>novak djokov say decid greatest player time me...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  darkest corner grand museum look like neo clas...\n",
       "1  thousand reddit commun inaccess monday protest...\n",
       "2  novak djokov say decid greatest player time me..."
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = RegexpTokenizer('\\w+')\n",
    "stop_words=set(stopwords.words(\"english\"))\n",
    "#stemmer = PorterStemmer()\n",
    "\n",
    "def preprocess(string):\n",
    "    s = tokenizer.tokenize(string.lower()) # no stop words in training data, so need to remove here too\n",
    "    s = [word for word in s if word not in stop_words]\n",
    "#    s = [stemmer.stem(word) for word in s] # don't do this stemming because the training data wasn't stemmed (want training and testing data to be similar, so process them the same)\n",
    "    return ' '.join(s)\n",
    "\n",
    "X_processed = pd.DataFrame([preprocess(X.loc[i, \"text\"]) for i in range(len(X))])\n",
    "X_processed\n",
    "# print(X_processed.loc[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "458b37ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 28975)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_vect = vect.transform(X_processed[0])\n",
    "# print(X_vect)\n",
    "X_vect.shape # only 3 rows, as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "31cdc034",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "081a43bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entertainment article predicted as: Entertainment\n",
      "Tech article predicted as: Tech\n",
      "Sport article predicted as: Sport\n"
     ]
    }
   ],
   "source": [
    "# print(len(y_pred))\n",
    "actual = [\"Entertainment\", \"Tech\", \"Sport\"]\n",
    "for i in range(len(y_pred)):\n",
    "    print(actual[i], \"article predicted as:\", lookup[y_pred[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5558aeae",
   "metadata": {},
   "source": [
    "6e. Create a Raw NBConvert cell to __discuss the result of your test__."
   ]
  },
  {
   "cell_type": "raw",
   "id": "b116fadc",
   "metadata": {},
   "source": [
    "The model seems to be accurate! It correctly guessed the category of all 3 articles presented to it! That's so cool!! :) Although since only 3 articles here were chosen, the accuracy seems to be 100%, but the model won't actually always be right. But it's definitely really good!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
