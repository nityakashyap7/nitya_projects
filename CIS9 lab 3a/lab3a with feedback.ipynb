{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11548204",
   "metadata": {},
   "source": [
    "### CIS 9 - Lab 3a\n",
    "\n",
    "Supervised Learning: Regression and Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fcaf98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name: Nitya Kashyap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffce929",
   "metadata": {},
   "source": [
    "There are 2 parts to this lab, each part works with a different input file and solves a different type of ML problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18b42eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import sklearn.linear_model as lm\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104d0e8f",
   "metadata": {},
   "source": [
    "#### Part 1\n",
    "\n",
    "You're asked by a bank to create and train an ML model to predict whether a customer will accept an offer for a new credit card from the bank.\n",
    "\n",
    "One of the primary ways that a bank makes money is through interest from credit card accounts, so the bank would like to know which customers would be more likely to accept a credit card offer, given their banking status.\n",
    "\n",
    "The input fle is `cc.csv` ([source](https://www.kaggle.com/datasets/thedevastator/unlocking-credit-card-offer-acceptance-trends-in?select=creditcardmarketing-bbm.csv))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f071db26",
   "metadata": {},
   "source": [
    "1. Read and inspect data\n",
    "\n",
    "1a. __Read data from `cc.csv` into a DataFrame__.<br>\n",
    "Then __print the number of rows and columns of the DataFrame__<br>\n",
    "and __print the first 5 rows__.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c684792e",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'cc.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cc \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcc.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrows, columns:\u001b[39m\u001b[38;5;124m\"\u001b[39m, cc\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfirst 5 rows:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'cc.csv'"
     ]
    }
   ],
   "source": [
    "cc = pd.read_csv(\"cc.csv\")\n",
    "print(\"rows, columns:\", cc.shape)\n",
    "print(\"first 5 rows:\")\n",
    "cc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89b71789",
   "metadata": {},
   "outputs": [],
   "source": [
    "### this should be easily fixed by re-running the cell.    \n",
    "### As a result, there is no output to show your work for the entire notebook.   -2pts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d45aa4",
   "metadata": {},
   "source": [
    "1b. The `Offer Accepted` value of 'Yes' is of interest to the bank.<br> \n",
    "__Show the number of 'Yes' and 'No' in the `Offer Accepted` column__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409ff839",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cc[\"Offer Accepted\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9a5c50",
   "metadata": {},
   "source": [
    "2. Data Cleaning\n",
    "\n",
    "2a. __Show the number of NaNs__ in each column, and __drop any rows with NaN__.<br>\n",
    "Then __print the number of rows and columns of the DataFrame__ to confirm that there are still a majority of data available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0cdaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"check for NaNs:\")\n",
    "print(cc.isna().sum())\n",
    "cc = cc.dropna()\n",
    "print(\"\\ncleaned data rows, columns:\", cc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ecca11",
   "metadata": {},
   "source": [
    "2b. It looks like the `Average Balance` column is the average of the `Q1, Q2, Q3, Q4 Balances`.<br>\n",
    "Write code to __confirm that the `Average Balance` is the same as the average of the last 4 balance columns__.\n",
    "\n",
    "_You should not have to use a loop to check. Instead, think of how pandas (numpy) checks for the count of boolean results_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa36d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkAvg = cc[\"Average Balance\"]*4-cc[\"Q1 Balance\"]-cc[\"Q2 Balance\"]-cc[\"Q3 Balance\"]-cc[\"Q4 Balance\"]\n",
    "print(np.sum(checkAvg==0), \"of the\", cc.shape[0], \"rows have an Average Balance value that's the same as the average of the last 4 balance columns.\")\n",
    "# checkAvg[checkAvg==0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0ea8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### use numpy or pandas mean(), no need to multiply and subtract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65ac248",
   "metadata": {},
   "source": [
    "2c. Since the `Average Balance` is representative of the 4 quarter balances, __remove the `Q1, Q2, Q3, Q4 Balances`__.<br>\n",
    "Also __remove any additional columns that will not be helpful to the ML model__.<br>\n",
    "Then __print the first 5 rows of the DataFrame__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7933b34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.dtypes\n",
    "cc[\"Q1 Balance\"]\n",
    "cc.drop(columns=[\"Q1 Balance\", \"Q2 Balance\", \"Q3 Balance\", \"Q4 Balance\", \"Customer Number\", \"index\"], inplace=True)\n",
    "cc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb84920",
   "metadata": {},
   "source": [
    "2d. Create a Raw NBConvert cell to __explain why you removed the additional columns__ of step 2c."
   ]
  },
  {
   "cell_type": "raw",
   "id": "ebd3e8c0",
   "metadata": {},
   "source": [
    "Customer Number and index are both unique identifiers of each row, which does not pertain to the model's predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1690a0",
   "metadata": {},
   "source": [
    "3. Data Preparation\n",
    "\n",
    "3a. __Change all the \"Yes\" strings to the number 1, and all the \"No\" strings to the number 0__ in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4716d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "yn = {\"Yes\":1, \"No\":0}\n",
    "cc.replace(yn,inplace=True)\n",
    "# cc.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1731a97d",
   "metadata": {},
   "source": [
    "3b. __Print all the unique values of `Income Level` and of `Credit Rating`__ to confirm that both columns use the 3 values: Low, Medium, High.<br>\n",
    "Then __change \"Low\" to 0, \"Medium\" to 1, and \"High\" to 2__ in the DataFrame<br>\n",
    "and __print the first 5 rows__ to check your result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c74547",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Unique Income Level values: {', '.join(set(cc['Income Level']))}\")\n",
    "print(f\"Unique Credit Rating values: {', '.join(set(cc['Credit Rating']))}\")\n",
    "lmh = {\"Low\":0, \"Medium\":1, \"High\":2}\n",
    "cc.replace(lmh,inplace=True)\n",
    "cc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920cdd67",
   "metadata": {},
   "source": [
    "3c. __Change values of `Reward` and `Mailer Type` to numbers__<br>\n",
    "then __print the first 5 rows of the DataFrame__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8de44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Unique Reward values: {', '.join(set(cc['Reward']))}\")\n",
    "print(f\"Unique Mailer Type values: {', '.join(set(cc['Mailer Type']))}\")\n",
    "rewards = {\"Points\":1, \"Air Miles\":2, \"Cash Back\":3}\n",
    "mailertypes = {\"Postcard\":1, \"Letter\":2}\n",
    "cc.replace(rewards,inplace=True)\n",
    "cc.replace(mailertypes,inplace=True)\n",
    "cc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516b6989",
   "metadata": {},
   "source": [
    "3d. __Print the data type of each column__ to confirm that all values in the DataFrame is a number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b7eb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"data types:\\n\", cc.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1994d817",
   "metadata": {},
   "source": [
    "4. Data Analysis\n",
    "\n",
    "4a. Create a plot with 12 subplots to __show the distribution of each feature__ (column).<br>\n",
    "The plot should be 2 rows of 6 subplots each, and each subplot should have a title to specify which distribution is shown.\n",
    "\n",
    "_You should use a loop to create the 12 subplots, don't copy-paste code 12 times_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9479a342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(cc.columns)\n",
    "plt.figure(figsize=(20,5))\n",
    "i = 1\n",
    "for col in cc.columns:\n",
    "    plt.subplot(2, 6, i)\n",
    "    plt.title(col)\n",
    "    plt.hist(cc[col])\n",
    "    plt.plot()\n",
    "    i += 1\n",
    "plt.subplots_adjust(hspace=0.6,wspace=1)\n",
    "# plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697a5498",
   "metadata": {},
   "source": [
    "4c. Create a Raw NBConvert cell to __explain whether there are outliers or anything unusual__ in any of the features."
   ]
  },
  {
   "cell_type": "raw",
   "id": "cd951f85",
   "metadata": {},
   "source": [
    "In the # Homes Owned plot, it can be seen that the number of people who own 3 or more homes is very little. This seems like a potential outlier. The same goes for the number of people who hold more 4 or more credit cards and the number of people with 3 or more bank accounts open."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc33220",
   "metadata": {},
   "outputs": [],
   "source": [
    "### there are outliers with Household Size and Average Balance    -1/4pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46875b57",
   "metadata": {},
   "source": [
    "5. Create training and testing datasets\n",
    "\n",
    "5a. __Create the X and y datasets__<br>\n",
    "and __show the number of rows and columns of each dataset__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f4b27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cc.drop(columns=[\"Offer Accepted\"])\n",
    "y = cc[\"Offer Accepted\"]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac749a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "### no need to print y. There are more y values than can be printed anyway"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d71e63",
   "metadata": {},
   "source": [
    "5b. __Create the training and testing sets__ and __show their dimensions__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5f843b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "print(\"X train, X test, y train, y test:\", X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523eaa19",
   "metadata": {},
   "source": [
    "6. Train and measure the accuracy of appropriate ML models. <br>\n",
    "\n",
    "__Create, train, test, and evaluate the accuracy of _all_ the appropriate machine learning models__ that we've discussed in class to predict the customer response.<br>\n",
    "\n",
    "- It's a good idea to create one or more Code cells for _each_ type of machine learning model.<br>\n",
    "(Don't have one huge Code cell that has all the models, it makes debugging more difficult)\n",
    "- For each model, make sure to show all the accuracy measurements that we've discussed in class for the model.<br>\n",
    "_(Hint: there is more than one measurement)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ca88d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree classifier\n",
    "# train\n",
    "dtc = DecisionTreeClassifier()\n",
    "dtc = dtc.fit(X_train, y_train)\n",
    "# test\n",
    "y_pred = dtc.predict(X_test)\n",
    "# evaluate (accuracy score, confusion matrix, f1 score)\n",
    "print(\"Decision Tree Classifier performance metrics:\")\n",
    "print(\"Accuracy score:\", metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(y_test, y_pred, labels=[0,1]))\n",
    "print(\"F1 score:\", f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22f87df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree classifier\n",
    "# train\n",
    "rfc = RandomForestClassifier()\n",
    "rfc = rfc.fit(X_train, y_train)\n",
    "# test\n",
    "y_pred = rfc.predict(X_test)\n",
    "# evaluate (accuracy score, confusion matrix, f1 score)\n",
    "print(\"Decision Forest Classifier performance metrics:\")\n",
    "print(\"Accuracy score:\", metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(y_test, y_pred, labels=[0,1]))\n",
    "print(\"F1 score:\", f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f526c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNeighborsClassifier classifier\n",
    "# train\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn = knn.fit(X_train, y_train)\n",
    "# test\n",
    "y_pred = knn.predict(X_test)\n",
    "# evaluate (accuracy score, confusion matrix, f1 score)\n",
    "print(\"K-Neighbors Classifier performance metrics:\")\n",
    "print(\"Accuracy score:\", metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(y_test, y_pred, labels=[0,1]))\n",
    "print(\"F1 score:\", f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4754d87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### find the optimum number for N and use it for the model    -1pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9233d9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gausian Naive Bayes classifier\n",
    "# train\n",
    "gnb = GaussianNB()\n",
    "gnb = gnb.fit(X_train, y_train)\n",
    "# test\n",
    "y_pred = gnb.predict(X_test)\n",
    "# evaluate (accuracy score, confusion matrix, f1 score)\n",
    "print(\"Gausian Naive Bayes Classifier performance metrics:\")\n",
    "print(\"Accuracy score:\", metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(y_test, y_pred, labels=[0,1]))\n",
    "print(\"F1 score:\", f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac25af0",
   "metadata": {},
   "source": [
    "7. Based on the accuracy measurements, what would you recommend to the bank?<br>\n",
    "Create a Raw NBConvert to show your recommendation."
   ]
  },
  {
   "cell_type": "raw",
   "id": "0d92e455",
   "metadata": {},
   "source": [
    "Based on the F1-score, K Nearest Neighbor classifier performs best for this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871d8b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### the confusion matrix result shows that the models are bad at predicting customers \n",
    "### who would accept credit cards.\n",
    "### Need more data        -1/2pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcfc4dc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96a2043",
   "metadata": {},
   "source": [
    "#### Part 2\n",
    "\n",
    "Create and train an ML model to predict the price of a house, given some common features of the house.<br>\n",
    "The input file is `house.csv` ([source](https://www.kaggle.com/datasets/praveenobulreddy/usa-housing-dataset))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0124785f",
   "metadata": {},
   "source": [
    "1. Read and inspect data\n",
    "\n",
    "1a. __Read data from `house.csv` into a DataFrame__.<br>\n",
    "Then __print the number of rows and columns of the DataFrame__<br>\n",
    "and __print the first 5 rows__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e4f1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = pd.read_csv(\"house.csv\")\n",
    "print(\"Number of rows, columns: \", hp.shape)\n",
    "hp.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11098d43",
   "metadata": {},
   "source": [
    "1b. __Remove any unnecessary columns__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662febbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.drop('Address', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8f63e0",
   "metadata": {},
   "source": [
    "1c. __Check for NaNs and drop rows with NaNs__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a41f9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "if(hp.isna().values.any()):\n",
    "    print ('There are NaNs in the data')\n",
    "    hp.dropna(axis=0, how='any', inplace=True)\n",
    "else:\n",
    "    print ('There is no NaN in the data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bdea29",
   "metadata": {},
   "source": [
    "2. Data Cleaning\n",
    "\n",
    "__Shorten the column headers to the last word__ only.<br>\n",
    "For example, \"Avg. Area Income\" becomes \"Income\"<br>\n",
    "Then __show the first 5 rows of the DataFrame__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73347596",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.columns = hp.columns.str.extract('([a-zA-Z]+)$', expand=False)\n",
    "hp.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60268182",
   "metadata": {},
   "source": [
    "3. Data Analysis\n",
    "\n",
    "3a. __Plot the distribution of the Price__ column<br>\n",
    "The plot should have a title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34eaa307",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Distribution of home prices\")\n",
    "plt.xlabel(\"prices in millions of dollars\",fontsize=12)\n",
    "plt.ylabel(\"frequency\",fontsize=12)\n",
    "plt.hist(hp.Price, bins=25)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba233b8b",
   "metadata": {},
   "source": [
    "3b. Create a Raw NBConvert cell to __explain whether the data is balanced__, based on the plot."
   ]
  },
  {
   "cell_type": "raw",
   "id": "50b4cf34",
   "metadata": {},
   "source": [
    "Price column in the dataset is balanced since the distribution is uniform. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a6163d",
   "metadata": {},
   "source": [
    "3c. Create a plot with 5 subplots to __show any correlation between each feature and the price__.<br>\n",
    "The plot should be in 2 rows of 2-3 subplots each, and each subplot should have a title to specify which distribution is shown.\n",
    "\n",
    "_You should use a loop to create the subplots._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8996c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,4))\n",
    "for i, col in enumerate(hp.columns):\n",
    "    if(col!='Price'):\n",
    "        plt.subplot(2,3,i+1)\n",
    "        plt.title(col+' vs. '+'Price')\n",
    "        plt.scatter(hp[col],hp.Price)\n",
    "        plt.xlabel(col)\n",
    "        plt.ylabel('Home price')\n",
    "plt.subplots_adjust(hspace=0.6,wspace=0.4)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa521faf",
   "metadata": {},
   "source": [
    "3d. Is there any correlation between the features and the price?<br>\n",
    "Create a Raw NBConvert to __explain any correlation__."
   ]
  },
  {
   "cell_type": "raw",
   "id": "9801899b",
   "metadata": {},
   "source": [
    "The scatter plots show that home price is correlated to avg area income. Correlation of price to avg area house age, number of rooms, and population is weak. Price is not correlated to average area number of bedrooms.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d52ad3",
   "metadata": {},
   "source": [
    "4.Create training and testing datasets\n",
    "\n",
    "4a. __Create the X and y datasets__<br>\n",
    "and __show the number of rows and columns of each dataset__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22350c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = hp[['Income','Age', 'Rooms', 'Bedrooms', 'Population']]\n",
    "y = hp.Price\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c00ce0",
   "metadata": {},
   "source": [
    "4b. __Create the training and testing sets__ and __show their dimensions__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8716981",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1727fa16",
   "metadata": {},
   "source": [
    "5. Train and measure accuracy of appropriate ML models. <br>\n",
    "\n",
    "__Create, train, test, and evaluate the accuracy of _all_ the appropriate machine learning models__ that we've discussed in class to predict the customer response.<br>\n",
    "\n",
    "- It's a good idea to create one or more Code cells for _each_ type of machine learning model.<br>\n",
    "(Don't have one huge Code cell that has all the models, it makes debugging more difficult)\n",
    "- For each model, make sure to show all the accuracy measurements that we've discussed in class for the model.<br>\n",
    "_(Hint: there is more than one measurement)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169dd3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = lm.LinearRegression()\n",
    "regr = regr.fit(X_train, y_train)\n",
    "coeff = pd.DataFrame(regr.coef_, X.columns, columns=['Coefficient'])\n",
    "print(\"Linear Regression:\")\n",
    "coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88eeb87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regr.predict(X_test)\n",
    "df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "RMSE = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "priceMean = np.mean(y)\n",
    "print('Root Mean Squared Error:',round(RMSE,2),\"or\",round(RMSE/priceMean*100),\"percent error\")\n",
    "print('R^2 value:', round(regr.score(X,y),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92de37b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = DecisionTreeRegressor()\n",
    "regr = regr.fit(X_train, y_train)\n",
    "# from sklearn import tree\n",
    "# matplotlib.rcParams['figure.figsize'] = (10, 8)\n",
    "# tree.plot_tree(regr, fontsize=10)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266f045f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regr.predict(X_test)\n",
    "df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "print(df.shape)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9683967a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### don't need to print the DataFrame. Most people will not read through 1500 rows of data\n",
    "### to compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f13e17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.DataFrame(regr.feature_importances_, X.columns, columns=['Importance'])\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6417ddb",
   "metadata": {},
   "source": [
    "6. For the models that you used, do they have the same list of important features?\n",
    "Create a Raw NBConvert cell to __compare the lists of important features__."
   ]
  },
  {
   "cell_type": "raw",
   "id": "331e33b1",
   "metadata": {},
   "source": [
    "Multiple Linear Regression shows Age and Rooms are the most important features. In contrast, Decision Tree Regressor shows Income and Age are the most important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1276eb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 21.25pts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
